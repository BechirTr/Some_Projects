{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e4c8d3bc79b04399a6a72af2f2c374ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76895d045a654518a6806ec23bcb9606",
              "IPY_MODEL_a89454dd2d324d12b23b5745f46034d2",
              "IPY_MODEL_ac370c791b014b609eed9cafbf6bbd7a"
            ],
            "layout": "IPY_MODEL_25e74f77e62e423f8ed4e7649790ce15"
          }
        },
        "76895d045a654518a6806ec23bcb9606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39fee6b47bf54874842adf63b783d1ae",
            "placeholder": "​",
            "style": "IPY_MODEL_3d270a02ea6d458a88bc950ef0cfe634",
            "value": "Map: 100%"
          }
        },
        "a89454dd2d324d12b23b5745f46034d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2cbb4a4ed5c4ec2b7c85fc5a89bde83",
            "max": 800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1c8ea14e36e4147a4c6b53149e14628",
            "value": 800
          }
        },
        "ac370c791b014b609eed9cafbf6bbd7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4265f85f87c4a32b756899427a78a36",
            "placeholder": "​",
            "style": "IPY_MODEL_84660e55ac3e43968570c87f6335d28b",
            "value": " 800/800 [00:01&lt;00:00, 803.93 examples/s]"
          }
        },
        "25e74f77e62e423f8ed4e7649790ce15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39fee6b47bf54874842adf63b783d1ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d270a02ea6d458a88bc950ef0cfe634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2cbb4a4ed5c4ec2b7c85fc5a89bde83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1c8ea14e36e4147a4c6b53149e14628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4265f85f87c4a32b756899427a78a36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84660e55ac3e43968570c87f6335d28b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "869dd04af9df4b84a9c9cc45d609865a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db47439f72634c148cc5d55297774141",
              "IPY_MODEL_324ee03df3c7474ca99c4160c7eb5b19",
              "IPY_MODEL_d6c2b8f242c5473fa466fbb1200c8ed2"
            ],
            "layout": "IPY_MODEL_a3cbc0721d26410e9934c655f8fe3d0d"
          }
        },
        "db47439f72634c148cc5d55297774141": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fae555f8e40d45d1966bd635696d9db6",
            "placeholder": "​",
            "style": "IPY_MODEL_cc69270561534fbfad42d47948ff951f",
            "value": "Map: 100%"
          }
        },
        "324ee03df3c7474ca99c4160c7eb5b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c46b245eef6484aa4d51963863a43a9",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8da401192e734f889b1f10a0d1568240",
            "value": 200
          }
        },
        "d6c2b8f242c5473fa466fbb1200c8ed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23a8f765e63a445484e6780fd7a24245",
            "placeholder": "​",
            "style": "IPY_MODEL_b0ff685d6b834e089c19c9fcedf803b5",
            "value": " 200/200 [00:00&lt;00:00, 683.26 examples/s]"
          }
        },
        "a3cbc0721d26410e9934c655f8fe3d0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fae555f8e40d45d1966bd635696d9db6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc69270561534fbfad42d47948ff951f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c46b245eef6484aa4d51963863a43a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8da401192e734f889b1f10a0d1568240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23a8f765e63a445484e6780fd7a24245": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0ff685d6b834e089c19c9fcedf803b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets accelerate peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH6qTW3-GJmt",
        "outputId": "ae6458cc-2d36-4cba-bcec-b641cc20dd34"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting peft\n",
            "  Downloading peft-0.11.1-py3-none-any.whl (251 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Collecting requests (from transformers)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: xxhash, requests, pyarrow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets, accelerate, peft\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.31.0 datasets-2.20.0 dill-0.3.8 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 peft-0.11.1 pyarrow-16.1.0 requests-2.32.3 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XtkZaeIguLkw"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "from datasets import load_dataset\n",
        "import random\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global credential.helper store"
      ],
      "metadata": {
        "id": "Kx1U-QDj0g6O"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login --token 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 --add-to-git-credential"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2hOIkJwzqBc",
        "outputId": "8dc65c11-5b3b-4841-9bad-85f20498bdc9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid (permission: read).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_synthetic_problem():\n",
        "    n_X_remaining = random.randint(1, 20)\n",
        "    n_Y_remaining = random.randint(1, 20)\n",
        "    cost_X = random.randint(5, 20)\n",
        "    cost_Y = random.randint(5, 20)\n",
        "    storage_cost = random.randint(1, 5)\n",
        "    price_X = random.randint(20, 40)\n",
        "    price_Y = random.randint(20, 40)\n",
        "    storage_limit = random.randint(400, 600)\n",
        "    historical_orders_X = [random.randint(10, 50) for _ in range(10)]\n",
        "    historical_orders_Y = [random.randint(10, 50) for _ in range(10)]\n",
        "\n",
        "    problem_description = f\"\"\"\n",
        "    I have {n_X_remaining} items of X and {n_Y_remaining} items of Y left in my inventory.\n",
        "    I want to know how much should I restock for the next week given that the cost of X is ${cost_X},\n",
        "    the cost of Y is ${cost_Y}, the cost of storage is ${storage_cost} per unit, the price of X is ${price_X},\n",
        "    the price of Y is ${price_Y}, the storage limit is {storage_limit} units, and here is a historical orders of X\n",
        "    of last year's orders in the same period: {', '.join(map(str, historical_orders_X))} and Y of last year's orders\n",
        "    in the same period: {', '.join(map(str, historical_orders_Y))}\n",
        "    \"\"\"\n",
        "\n",
        "    structured_output = {\n",
        "        'n_X_remaining': n_X_remaining,\n",
        "        'n_Y_remaining': n_Y_remaining,\n",
        "        'cost_X': cost_X,\n",
        "        'cost_Y': cost_Y,\n",
        "        'storage_cost': storage_cost,\n",
        "        'price_X': price_X,\n",
        "        'price_Y': price_Y,\n",
        "        'storage_limit': storage_limit,\n",
        "        'historical_orders_X': historical_orders_X,\n",
        "        'historical_orders_Y': historical_orders_Y\n",
        "    }\n",
        "\n",
        "    return problem_description, structured_output\n",
        "\n",
        "def generate_synthetic_dataset(num_samples):\n",
        "    dataset = []\n",
        "    for _ in range(num_samples):\n",
        "        problem_description, structured_output = generate_synthetic_problem()\n",
        "        dataset.append({\n",
        "            'instruction': 'Extract the following parameters from the text',\n",
        "            'input': problem_description,\n",
        "            'output': structured_output\n",
        "        })\n",
        "    return dataset\n",
        "\n",
        "def save_dataset_to_json(dataset, filename):\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(dataset, f, indent=4)\n",
        "\n",
        "\n",
        "num_samples = 1000\n",
        "synthetic_dataset = generate_synthetic_dataset(num_samples)\n",
        "\n",
        "\n",
        "save_dataset_to_json(synthetic_dataset, 'synthetic_instruct_dataset.json')"
      ],
      "metadata": {
        "id": "MGd5Fu9CGbEa"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset('json', data_files='synthetic_instruct_dataset.json')\n",
        "dataset = dataset['train'].train_test_split(test_size=0.2)"
      ],
      "metadata": {
        "id": "nkG1B_D1x4hA"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX4vPfKFJah1",
        "outputId": "13df8ecf-54de-4915-a11c-0c614d650473"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['instruction', 'input', 'output'],\n",
              "        num_rows: 800\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['instruction', 'input', 'output'],\n",
              "        num_rows: 200\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset['test'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6FzO01EHtd8",
        "outputId": "1d0daa0d-7969-43e2-90d5-a4cb41872eac"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'instruction': 'Extract the following parameters from the text', 'input': \"\\n    I have 17 items of X and 15 items of Y left in my inventory.\\n    I want to know how much should I restock for the next week given that the cost of X is $17, \\n    the cost of Y is $6, the cost of storage is $1 per unit, the price of X is $29, \\n    the price of Y is $32, the storage limit is 523 units, and here is a historical orders of X \\n    of last year's orders in the same period: 21, 25, 44, 26, 49, 38, 49, 17, 37, 19 and Y of last year's orders \\n    in the same period: 50, 11, 21, 19, 25, 20, 42, 44, 22, 40\\n    \", 'output': {'cost_X': 17, 'cost_Y': 6, 'historical_orders_X': [21, 25, 44, 26, 49, 38, 49, 17, 37, 19], 'historical_orders_Y': [50, 11, 21, 19, 25, 20, 42, 44, 22, 40], 'n_X_remaining': 17, 'n_Y_remaining': 15, 'price_X': 29, 'price_Y': 32, 'storage_cost': 1, 'storage_limit': 523}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "dataset = load_dataset('json', data_files='synthetic_instruct_dataset.json')\n",
        "\n",
        "\n",
        "model_name = 'google/flan-t5-small'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHoP54EvHY8D",
        "outputId": "d402b943-0dda-4d3f-abe8-6a56ad827dfc"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 512)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 6)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-7): 7 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 6)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-7): 7 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    inputs = [instruction + \": \" + input_text for instruction, input_text in zip(examples['instruction'], examples['input'])]\n",
        "    targets = [str(output) for output in examples['output']]\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=512, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "\n",
        "tokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=dataset['train'].column_names)\n",
        "\n",
        "\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['test'],\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364,
          "referenced_widgets": [
            "e4c8d3bc79b04399a6a72af2f2c374ca",
            "76895d045a654518a6806ec23bcb9606",
            "a89454dd2d324d12b23b5745f46034d2",
            "ac370c791b014b609eed9cafbf6bbd7a",
            "25e74f77e62e423f8ed4e7649790ce15",
            "39fee6b47bf54874842adf63b783d1ae",
            "3d270a02ea6d458a88bc950ef0cfe634",
            "f2cbb4a4ed5c4ec2b7c85fc5a89bde83",
            "e1c8ea14e36e4147a4c6b53149e14628",
            "d4265f85f87c4a32b756899427a78a36",
            "84660e55ac3e43968570c87f6335d28b",
            "869dd04af9df4b84a9c9cc45d609865a",
            "db47439f72634c148cc5d55297774141",
            "324ee03df3c7474ca99c4160c7eb5b19",
            "d6c2b8f242c5473fa466fbb1200c8ed2",
            "a3cbc0721d26410e9934c655f8fe3d0d",
            "fae555f8e40d45d1966bd635696d9db6",
            "cc69270561534fbfad42d47948ff951f",
            "8c46b245eef6484aa4d51963863a43a9",
            "8da401192e734f889b1f10a0d1568240",
            "23a8f765e63a445484e6780fd7a24245",
            "b0ff685d6b834e089c19c9fcedf803b5"
          ]
        },
        "id": "4hJ5iklBHhWu",
        "outputId": "f99d6921-a61e-4e26-ce73-91550c4fb7ac"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4c8d3bc79b04399a6a72af2f2c374ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "869dd04af9df4b84a9c9cc45d609865a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 04:46, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.017190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.128104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.751700</td>\n",
              "      <td>0.060170</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=600, training_loss=2.332410872777303, metrics={'train_runtime': 287.1358, 'train_samples_per_second': 8.358, 'train_steps_per_second': 2.09, 'total_flos': 446137211289600.0, 'train_loss': 2.332410872777303, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "def test_model(user_input, instruction=\"Extract the following parameters from the text\"):\n",
        "\n",
        "    input_text = instruction + \": \" + user_input\n",
        "\n",
        "\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n",
        "\n",
        "\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs, max_length=512, num_beams=4, early_stopping=True)\n",
        "\n",
        "\n",
        "    decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return decoded_output\n",
        "\n",
        "\n",
        "user_input = \"\"\"\n",
        "I have 227 items of X and 212 items of Y left in my inventory.\n",
        "I want to know how much should I restock for the next week given that the cost of X is $5,\n",
        "the cost of Y is $15, the cost of storage is $1 per unit, the price of X is $33,\n",
        "the price of Y is $37, the storage limit is 498 units, and here is a historical orders of X\n",
        "of last year's orders in the same period: 26, 25, 29, 17, 49, 33, 46, 42, 30, 33 and Y of last year's orders\n",
        "in the same period: 31, 26, 50, 25, 21, 16, 21, 39, 27, 45\n",
        "\"\"\"\n",
        "\n",
        "result = test_model(user_input)\n",
        "print(\"Extracted Variables:\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_K73jBrEKAXK",
        "outputId": "54aa57b8-d2d7-480e-8e28-41cfc23479f6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Variables: 'cost_X': 5, 'cost_Y': 15, 'historical_orders_X': [26, 25, 29, 17, 49, 33, 46, 42, 30, 33], 'historical_orders_Y': [31, 26, 50, 25, 21, 16, 21, 39, 27, 45], 'n_X_remaining': 2, 'n_Y_remaining': 3, 'price_X': 3, 'price_Y': 3,'storage_cost': 1,'storage_limit': 498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "def parse_parameters(text):\n",
        "\n",
        "    return ast.literal_eval(\"{\" + text + \"}\")\n",
        "\n",
        "parameters = parse_parameters(result)\n",
        "print(parameters)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR8NcYU_LP4n",
        "outputId": "98f9341b-708c-4f49-e5e8-5c02adff0cb8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'cost_X': 5, 'cost_Y': 15, 'historical_orders_X': [26, 25, 29, 17, 49, 33, 46, 42, 30, 33], 'historical_orders_Y': [31, 26, 50, 25, 21, 16, 21, 39, 27, 45], 'n_X_remaining': 2, 'n_Y_remaining': 3, 'price_X': 3, 'price_Y': 3, 'storage_cost': 1, 'storage_limit': 498}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mathematical Approach\n",
        "\n",
        "The goal is to solve the newsvendor problem where we want to determine optimal quantities $ q_X $ and $ q_Y $ to restock for products X and Y respectively, considering uncertain demand and costs associated with production and inventory management.\n",
        "\n",
        "#### Cost Function Definition\n",
        "\n",
        "The cost function $ K(q_X, q_Y) $ is formulated as follows:\n",
        "\n",
        "$$ K(q_X, q_Y) = c_X + c_Y + s \\cdot (q_X + q_Y + n_X + n_Y) + p_X \\cdot \\mathbb{E}\\left[\\max(D_X - q_X, 0)\\right] + p_Y \\cdot \\mathbb{E}\\left[\\max(D_Y - q_Y, 0)\\right] $$\n",
        "\n",
        "Where:\n",
        "- $ c_X $: Cost of restocking unit X.\n",
        "- $ c_Y $: Cost of restocking unit Y.\n",
        "- $ s $: Storage cost per unit.\n",
        "- $ q_X $: Quantity to restock for X.\n",
        "- $ q_Y $: Quantity to restock for Y.\n",
        "- $ n_X $: Remaining units of X.\n",
        "- $ n_Y $: Remaining units of Y.\n",
        "- $ p_X $: Price of X.\n",
        "- $ p_Y $: Price of Y.\n",
        "- $ D_X $: Demand distribution for X.\n",
        "- $ D_Y $: Demand distribution for Y.\n",
        "- $ \\mathbb{E}[D_X] $: Expected demand for X.\n",
        "- $ \\mathbb{E}[D_Y] $: Expected demand for Y.\n",
        "\n",
        "#### Objective Function\n",
        "\n",
        "The objective is to minimize the total expected cost $ K(q_X, q_Y) $:\n",
        "\n",
        "$$ \\text{Objective: } \\min_{q_X, q_Y} \\left[ c_X + c_Y + s \\cdot (q_X + q_Y + n_X + n_Y) + p_X \\cdot \\mathbb{E}\\left[\\max(D_X - q_X, 0)\\right] + p_Y \\cdot \\mathbb{E}\\left[\\max(D_Y - q_Y, 0)\\right] \\right] $$\n",
        "\n",
        "#### Constraints\n",
        "\n",
        "1. **Storage Constraint**: Ensure the total restocked quantity does not exceed the storage limit:\n",
        "   $$ q_X + q_Y + n_X + n_Y \\leq \\text{storage\\_limit} $$\n",
        "\n",
        "2. **Integer Constraints**: Restocking quantities $ q_X $ and $ q_Y $ must be positive integers:\n",
        "   $$ q_X \\geq 1, \\quad q_Y \\geq 1 $$\n",
        "\n",
        "### Example Usage\n",
        "\n",
        "To solve this problem programmatically using Python, we integrate these equations into an optimization function that finds $ q_X $ and $ q_Y $ that minimize the total expected cost considering the defined constraints and parameters.\n"
      ],
      "metadata": {
        "id": "oXkexkhXQ-8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "\n",
        "def solve_newsvendor_problem(n_X_remaining, n_Y_remaining, cost_X, cost_Y, storage_cost, price_X, price_Y, storage_limit, historical_orders_X, historical_orders_Y):\n",
        "    # Calculate mean demand from historical orders\n",
        "    mean_demand_X = np.mean(historical_orders_X)\n",
        "    mean_demand_Y = np.mean(historical_orders_Y)\n",
        "\n",
        "    # Assume a random fixed cost\n",
        "    fixed_cost = np.random.randint(100, 500)\n",
        "\n",
        "    # Objective function to minimize total cost\n",
        "    def objective(q):\n",
        "        expected_shortage_X = np.mean(np.maximum(mean_demand_X - q[0], 0))\n",
        "        expected_shortage_Y = np.mean(np.maximum(mean_demand_Y - q[1], 0))\n",
        "        expected_inventory_X = np.mean(np.maximum(q[0] - mean_demand_X, 0))\n",
        "        expected_inventory_Y = np.mean(np.maximum(q[1] - mean_demand_Y, 0))\n",
        "\n",
        "        total_cost_X = cost_X + storage_cost * q[0] + price_X * expected_shortage_X\n",
        "        total_cost_Y = cost_Y + storage_cost * q[1] + price_Y * expected_shortage_Y\n",
        "\n",
        "        return total_cost_X + total_cost_Y + fixed_cost + storage_cost * (q[0] + q[1])\n",
        "\n",
        "    # Constraints\n",
        "    def storage_constraint(q):\n",
        "        return storage_limit - (q[0] + q[1] + n_X_remaining + n_Y_remaining)\n",
        "\n",
        "    def integer_constraint_X(q):\n",
        "        return q[0] - 1  # Ensure q[0] >= 1 (X restock quantity)\n",
        "\n",
        "    def integer_constraint_Y(q):\n",
        "        return q[1] - 1  # Ensure q[1] >= 1 (Y restock quantity)\n",
        "\n",
        "    constraints = [\n",
        "        {'type': 'ineq', 'fun': storage_constraint},\n",
        "        {'type': 'ineq', 'fun': integer_constraint_X},\n",
        "        {'type': 'ineq', 'fun': integer_constraint_Y}\n",
        "    ]\n",
        "\n",
        "    # Initial guess\n",
        "    initial_guess = [max(1, mean_demand_X - n_X_remaining), max(1, mean_demand_Y - n_Y_remaining)]\n",
        "\n",
        "    # Solve the optimization problem\n",
        "    result = minimize(objective, initial_guess, constraints=constraints, method='SLSQP')\n",
        "\n",
        "    return result.x if result.success else None\n",
        "\n",
        "\n",
        "\n",
        "def restock_decision(user_input):\n",
        "    model_result = test_model(user_input)\n",
        "    parsed_data = parse_parameters(result)\n",
        "    solution = solve_newsvendor_problem(\n",
        "        parsed_data['n_X_remaining'],\n",
        "        parsed_data['n_Y_remaining'],\n",
        "        parsed_data['cost_X'],\n",
        "        parsed_data['cost_Y'],\n",
        "        parsed_data['storage_cost'],\n",
        "        parsed_data['price_X'],\n",
        "        parsed_data['price_Y'],\n",
        "        parsed_data['storage_limit'],\n",
        "        parsed_data['historical_orders_X'],\n",
        "        parsed_data['historical_orders_Y']\n",
        "    )\n",
        "\n",
        "    if solution is not None:\n",
        "        restock_X, restock_Y = solution\n",
        "        return f\"Restock {int(restock_X):.2f} units of X and {int(restock_Y):.2f} units of Y.\"\n",
        "    else:\n",
        "        return \"Could not find a feasible solution.\"\n"
      ],
      "metadata": {
        "id": "kqcdY4b2NNSh"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"\"\"\n",
        "I have 5 items of X and 2 items of Y left in my inventory.\n",
        "I want to know how much should I restock for the next week given that the cost of X is $5,\n",
        "the cost of Y is $15, the cost of storage is $2 per unit, the price of X is $33,\n",
        "the price of Y is $37, the storage limit is 100 units, and here is a historical orders of X\n",
        "of last year's orders in the same period: 26, 25, 29, 17, 49, 33, 46, 42, 30, 33 and Y of last year's orders\n",
        "in the same period: 31, 26, 50, 25, 21, 16, 21, 39, 27, 45\n",
        "\"\"\"\n",
        "restock_decision(user_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LBmHr_2BO56z",
        "outputId": "2513c912-a67d-4e8a-d091-f9888e84e53f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Restock 33.00 units of X and 30.00 units of Y.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FKT9TqKEPFdC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}